# -*- coding: utf-8 -*-
"""A2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1chTxBPgw7lYM1g6_ppAaeT3v7FQUvHkg

# Assignment 2: Analogies

For all subsests, in English on the [Google Analogies Dataset](http://download.tensorflow.org/data/questions-words.txt) solve them using the parallelogram model. Which kind of analogies are solved better? Hypotheses as to why? Do you notice any patterns in the mistakes?

### Step 1: Select & Setup the Model
"""

# Setup our Glove Model
## Inspiration taken from here: https://github.com/piskvorky/gensim-data#quickstart

import gensim.downloader as api

# choose wikipedia because i think formal writing would work better, but if
# you have other ideas for better corpuses to train on we can try it out too
model = api.load("glove-wiki-gigaword-200")

# twitter model
## model = api.load("glove-twitter-100")

"""### Step 2: Prepare the analogies dataset

"""

# Download the analogies dataset
!wget http://download.tensorflow.org/data/questions-words.txt -O analogies.txt

"""### Step 2.1 Create a list of analogies"""

# load the entire text as a variable
## Inspiration taken from: https://www.askpython.com/python/examples/read-file-as-string-in-python

with open('analogies.txt') as f:
  analogies = f.read()

# now we have the entire list in one variable
# print(analogies)

# split our string into a list, with each element being a line in our text
## Inspiration: https://www.programiz.com/python-programming/methods/string/split

list_analogies = analogies.split("\n") # the \n character represents a newline or an enter in the text

# print the first 5 lines
print(list_analogies[:5])

# remove the last line in our list because it is an empty string
print(f"Previous last line: {list_analogies[-1]}")
list_analogies = list_analogies[:-1]
print(f"New last line: {list_analogies[-1]}")

"""### Step 2.2 Organize our list of analogies into sets of words"""

# create a list for each word A, B, C and D
A_words = []
B_words = []
C_words = []
D_words = []

# create a list of labels as well
labels = []
label = ""

# go through our list of analogies and organize each word into the proper category
for analogy in list_analogies:
  # if the line contains a ":" we know its a label
  if ":" in analogy:
    # split the label line by " " and take the second word
    label = analogy.split(" ")[1]


  # if it's not a label we split up the analogies
  else:
    words = analogy.split(" ")

    # add A,B,C and D words to their respective lists
    A_words.append(words[0].lower()) # we know the first word is A
    B_words.append(words[1].lower())
    C_words.append(words[2].lower())
    D_words.append(words[3].lower())

    # also add the label we got above to label these set of words
    labels.append(label)

i = 0
# now for the same index in our list we have a set that matches our original text
print(f"Set: {labels[i]}, {A_words[i]} {B_words[i]} {C_words[i]} {D_words[i]}")

"""### Step 2.3: Create a dataframe

To make it easier to use our lists from above we can create a dataframe by imagining each list as a column in our dataframe
"""

import pandas as pd

dataframe = pd.DataFrame({
    "label": labels,
    "wordA": A_words,
    "wordB": B_words,
    "wordC": C_words,
    "wordD": D_words
})

dataframe.head()

"""### Step 3: Using GloVe create the parallelogram model"""

import numpy as np

# Given words A, B and C find wordD by
def parallelogram(wordA, wordB, wordC):

  # Calculate wordD vector
  wordD_vector = model.get_vector(wordB) - model.get_vector(wordA) + model.get_vector(wordC)

  # get word D using the similar by vector function
  # you can read more about it here: https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.similar_by_vector
  wordD, similarity = model.similar_by_vector(wordD_vector, topn=1)[0]


  return wordD

"""### Step 4: Apply the parallelogram model to our dataset







"""

# go through our dataframe and apply our parallelogram model
# this takes around 10 mins to run

model_guess = []

for _, row in dataframe.iterrows():
  wordA = row['wordA']
  wordB = row['wordB']
  wordC = row['wordC']

  # Add a new column called parallelogram which is the word our model selects
  model_guess.append(parallelogram(wordA, wordB, wordC))

dataframe['model_guess'] = model_guess

dataframe.to_csv('analogies_parallelogram_1.csv', index=False)

parallelogram('athens', 'greece', 'bangkok')

"""# Linguistic Analysis Parallelogram_1


"""

dataframe.head()

n_correct = len(dataframe.query('label == "capital-common-countries" and wordD == model_guess'))
n_total = len(dataframe.query('label == "capital-common-countries"'))

accuracy = n_correct / n_total
print(accuracy)

"""###Calculating the overall accuracy score

a) Calculate the number of correct model guesses
"""

# Calculate the number of matches between "wordD" and "model_guess"
n_matches = (dataframe['wordD'] == dataframe['model_guess']).sum()

print("Total number of matches:", n_matches)

"""b) Overall accuracy score (for all the words in the dataset and all labels)"""

# We divide the total number of matches by the total number of items(rows) in the dataframe

accuracy_all = n_matches/len(dataframe)
print(accuracy_all)

"""###Calculating accuracy scores corresponding to each label"""

# Get all unique labels from our dataframe
unique_labels = dataframe['label'].unique()
print(unique_labels)

# Initialize lists to store labels and accuracies
labels = []
accuracies = []

# Calculate accuracy for each unique label and store the results
for label in unique_labels:
    n_correct = len(dataframe.query(f'label == "{label}" and wordD == model_guess'))
    n_total = len(dataframe.query(f'label == "{label}" and wordD == wordD'))

    accuracy = n_correct / n_total
    labels.append(label)
    accuracies.append(accuracy)

# Create a DataFrame with labels and accuracy percentages
accuracy_df = pd.DataFrame({'Label': labels, 'Accuracy (%)': [f'{acc:.2%}' for acc in accuracies]})

print(accuracy_df)

# Plot the accuracy % by labels

import matplotlib.pyplot as plt

accuracy_df = pd.DataFrame({'Label': labels, 'Accuracy (%)': [f'{acc:.2%}' for acc in accuracies]})

# Define a function to determine the color based on the label
# we want to see semantic and morphological categories in different colors
def get_color(label):
    if label.startswith('gram'):
        return 'red'
    else:
        return 'green'



# Convert the 'Accuracy (%)' column to a numerical format for plotting
accuracy_df['Accuracy (%)'] = accuracy_df['Accuracy (%)'].str.rstrip('%').astype('float') / 100

# Sort the data frame by decreasing accuracy
accuracy_df = accuracy_df.sort_values(by='Accuracy (%)', ascending=True)

# Create a bar plot
fig, ax = plt.subplots()
bars = ax.barh(accuracy_df['Label'], accuracy_df['Accuracy (%)'], color=[get_color(label) for label in accuracy_df['Label']], align='center')
ax.bar_label(bars)
ax.set_xlabel('Accuracy')
ax.set_ylabel('Labels')
ax.set_title('Accuracy Corresponding to Different Labels')
plt.xlim(0, 1.1)  # Set the y-axis limits to 0-1 for % representation
plt.tight_layout()

# Show the plot
plt.show()

# compare overall accuracy between the two categories
grammatical_accuracy = len(dataframe.query('label.str.contains("gram") and wordD == model_guess')) / len(dataframe.query('label.str.contains("gram")'))
semantic_accuracy = len(dataframe.query('not label.str.contains("gram") and wordD == model_guess')) / len(dataframe.query('not label.str.contains("gram")'))

print(f"Grammatical accuracy: {grammatical_accuracy:.2%}")
print(f"Semantic accuraccy: {semantic_accuracy:.2%}")

# balanced comparison
# take 5000 random samples from each category
grammatical_samples = dataframe.query('label.str.contains("gram")').sample(n=5000)
semantic_samples = dataframe.query('not label.str.contains("gram")').sample(n=5000)

balanced_grammatical_accuracy = len(grammatical_samples.query('wordD == model_guess')) / len(grammatical_samples)
balanced_semantic_accuracy = len(semantic_samples.query('wordD == model_guess')) / len(semantic_samples)

print(f"Grammatical accuracy: {balanced_grammatical_accuracy:.2%}")
print(f"Semantic accuraccy: {balanced_semantic_accuracy:.2%}")

"""This gives us insights on what analogies are the most challenging for the model. Similar findings p. 11 in Rogers, Anna & Drozd, Aleksandr & Matsuoka, Satoshi. (2016). Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn't.. 8-15. 10.18653/v1/N16-2002. [link article](https://www.researchgate.net/publication/305334369_Analogy-based_detection_of_morphological_and_semantic_relations_with_word_embeddings_what_works_and_what_doesn%27t)

"""

#To have a look at the mismatching examples, we save them to csv

# Extract rows where wordD and model_guess do not match
mismatches_df = dataframe[dataframe['wordD'] != dataframe['model_guess']]

# Display the resulting DataFrame and the number of mismatching items
print(mismatches_df)
print(f'The number of mismatches between wordD and model guesses: {len(mismatches_df)}')

# Save the mismatching dataframe to a CSV file
mismatches_df.to_csv('mismatches_parallelogram_1.csv', index=False)

"""We observed that the current parallelogram model that we are using fails because most of the predicted results of wordD are one of the input words (wordA, wordB or wordC). This aligns with the results from Linzen, Tal. (2016). Issues in evaluating semantic spaces using word analogies. 1st Workshop on Evaluating Vector- Space Representations for NLP. Where it states: "A literal (“vanilla”) implementation of the method failed to perform the task: the nearest neighbor of a∗ − a + b was almost always b or a∗.1"

To prevent this from happening we added a heuristic in our function that selects the most similar word not including any of the input words.
"""

def parallelogram_2(wordA, wordB, wordC):

  # Calculate wordD vector
  wordD_vector = model.get_vector(wordB) - model.get_vector(wordA) + model.get_vector(wordC)

  # Find the top 2 similar words using the calculated wordD vector
  similar_words = model.similar_by_vector(wordD_vector, topn=5)

  # pick the first word that isn't an input word
  for word in similar_words:
    if word[0] not in [wordA, wordB, wordC]:
      return word[0]

# go through our dataframe and apply our parallelogram_2 model
# this takes around 10 mins to run

model_guess = []

for _, row in dataframe.iterrows():
  wordA = row['wordA']
  wordB = row['wordB']
  wordC = row['wordC']

  # Add a new column called parallelogram which is the word our model selects
  model_guess.append(parallelogram_2(wordA, wordB, wordC))

dataframe['model_2_guess'] = model_guess

dataframe.to_csv('analogies_parallelogram_2.csv', index=False)

"""# Linguistic Analysis with Parallelogram 2

a) Calculate the number of correct model guesses
"""

# Calculate the number of matches between "wordD" and "model_guess"
n_matches = (dataframe['wordD'] == dataframe['model_2_guess']).sum()

print("Total number of matches:", n_matches)

"""b) Overall accuracy score (for all the words in the dataset and all labels)"""

# We divide the total number of matches by the total number of items(rows) in the dataframe

accuracy_all = n_matches/len(dataframe)
print(accuracy_all)

"""c) Now we calculate accuracy score corresponding to each label"""

# Get all unique labels from our dataframe
unique_labels = dataframe['label'].unique()
print(unique_labels)

# Initialize lists to store labels and accuracies
labels = []
accuracies = []

# Calculate accuracy for each unique label and store the results
for label in unique_labels:
    n_correct = len(dataframe.query(f'label == "{label}" and wordD == model_2_guess'))
    n_total = len(dataframe.query(f'label == "{label}" and wordD == wordD'))

    accuracy = n_correct / n_total
    labels.append(label)
    accuracies.append(accuracy)

# Create a DataFrame with labels and accuracy percentages
accuracy_df = pd.DataFrame({'Label': labels, 'Accuracy (%)': [f'{acc:.2%}' for acc in accuracies]})

print(accuracy_df)

"""d) Visualise accuracy scores for each unique label

"""

# Plot the accuracy % by labels. (If you know a nicer way to do it, please share)

import matplotlib.pyplot as plt

accuracy_df = pd.DataFrame({'Label': labels, 'Accuracy (%)': [f'{acc:.2%}' for acc in accuracies]})

# Define a function to determine the color based on the label
def get_color(label):
    if label.startswith('gram'):
        return 'red'
    else:
        return 'green'



# Convert the 'Accuracy (%)' column to a numerical format for plotting
accuracy_df['Accuracy (%)'] = accuracy_df['Accuracy (%)'].str.rstrip('%').astype('float') / 100

# Sort the data frame by decreasing accuracy
accuracy_df = accuracy_df.sort_values(by='Accuracy (%)', ascending=True)

# Create a bar plot
fig, ax = plt.subplots()
bars = ax.barh(accuracy_df['Label'], accuracy_df['Accuracy (%)'], color=[get_color(label) for label in accuracy_df['Label']], align='center')
ax.bar_label(bars)
ax.set_xlabel('Accuracy')
ax.set_ylabel('Labels')
ax.set_title('Accuracy Corresponding to Different Labels')
plt.xlim(0, 1.1)  # Set the y-axis limits to 0-1 for % representation
plt.tight_layout()

# Show the plot
plt.show()

# compare overall accuracy between the two categories
grammatical_accuracy = len(dataframe.query('label.str.contains("gram") and wordD == model_2_guess')) / len(dataframe.query('label.str.contains("gram")'))
semantic_accuracy = len(dataframe.query('not label.str.contains("gram") and wordD == model_2_guess')) / len(dataframe.query('not label.str.contains("gram")'))

print(f"Grammatical accuracy: {grammatical_accuracy:.2%}")
print(f"Semantic accuraccy: {semantic_accuracy:.2%}")

# balanced comparison
# take 5000 random samples from each category
grammatical_samples = dataframe.query('label.str.contains("gram")').sample(n=5000)
semantic_samples = dataframe.query('not label.str.contains("gram")').sample(n=5000)

balanced_grammatical_accuracy = len(grammatical_samples.query('wordD == model_2_guess')) / len(grammatical_samples)
balanced_semantic_accuracy = len(semantic_samples.query('wordD == model_2_guess')) / len(semantic_samples)

print(f"Grammatical accuracy: {balanced_grammatical_accuracy:.2%}")
print(f"Semantic accuraccy: {balanced_semantic_accuracy:.2%}")

#To have a  look at the mismatching examples for Parallelogram_2 function, we save them to csv

# Extract rows where wordD and model_guess do not match
mismatches_df = dataframe[dataframe['wordD'] != dataframe['model_2_guess']]

# Display the resulting DataFrame and the number of mismatching items
print(mismatches_df)
print(f'The number of mismatches between wordD and model guesses: {len(mismatches_df)}')

# Save the mismatching dataframe to a CSV file
mismatches_df.to_csv('mismatches_parallelogram_2.csv', index=False)